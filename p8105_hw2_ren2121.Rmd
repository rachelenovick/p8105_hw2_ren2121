---
title: "p8105_hw2_ren2121"
output: html_document
date: "2025-09-26"
---

Loading libraries:

```{r}
library(tidyverse)
library(readxl)
library(lubridate)
library(knitr)
```

# Problem 1

Importing and cleaning the pols-month dataset:

```{r}

pols_month_df =
  read_csv("538_data/pols-month.csv", na = c("NA", ".", "")) |> 
  separate(mon, into = c("year", "month", "day")) |> 
   mutate(
    year = as.integer(year),
    month = as.integer(month),                 
    month = month.name[month],                  
    month = factor(month, levels = month.name),
    president = case_when(
      prez_dem == 1 ~ "dem",
      prez_dem == 0 ~ "gop")) |> 
  select(-prez_dem, -prez_gop, -day)

```

Importing and cleaning the snp dataset:

```{r}

snp_df =
  read_csv("538_data/snp.csv", na = c("NA", ".", "")) |> 
  separate(date, into = c("month", "day", "year")) |> 
  mutate(
    year = as.integer(year),
    month = as.integer(month),
    year = if_else(year >= 50, 1900 + year, 2000 + year),
    month = month.name[month],
    month = factor(month, levels = month.name)) |> 
  relocate(year, month) |> 
  arrange(year, month)

```

Importing and cleaning the unemployment dataset:

```{r}

unemployment_df =
  read_csv("538_data/unemployment.csv", na = c("NA", ".", "")) |> 
  pivot_longer(
    cols = Jan:Dec,
    names_to = "month",
    values_to = "unemployment") |> 
  mutate(
    year = as.integer(Year),                     
    month = month.name[match(month, month.abb)],
    month = factor(month, levels = month.name)) |>  
  select(-Year) |> 
  relocate(year)

```

Joining the datasets:

```{r}
snp_pols_df = 
  full_join(snp_df, pols_month_df, by = c("year", "month"))

full_df = 
  full_join(snp_pols_df, unemployment_df, by = c("year", "month")) |> 
  arrange(year, month)
```

**Description of the datasets**

The pols-month dataset has 822 observations and 9 variables (after cleaning), and provides information on the number of national politicians who are democratic or republican at any given time. It contains variables including: year, month, whether the president was republican or democrat, and the number of democratic and republic senators, governors, and representatives on those associated date.

The snp dataset has 787 observations and 4 variables (after cleaning), and provides information on the S&P. The variables included are: year, month, day, and close (the closing values of the S&P stock index on the associated date).

The unemployment dataset contains 68 observations and 3 variables (after cleaning), and provides information on the percentage of unemployment by date. The variables it includes are: year, month, and % unemployment associated with the month/year.

The resulting fully joined dataset has 828 observations and 12 variables: year, month, day, unemployment, president party, close, and the number of democratic and republican senators, governors, and representatives on the associated dates. The range of years included in the dataset is from 1947-2015.

# Problem 2

Reading in and cleaning the Mr. Trash Wheel dataset:

```{r}

mr_trash = 
  read_excel("2025_trash_data.xlsx", sheet = "Mr. Trash Wheel", range = "A2:N653") |> 
  janitor::clean_names() |> 
  drop_na(dumpster) |> 
  mutate(
    sports_balls = as.integer(round(sports_balls)),
    year = as.integer(year),
    day = day(date),  
    wheel = "mr") |> 
  select(-date) |>  
  relocate(wheel, .after = dumpster) |> 
  relocate(year, month, day, .after = wheel) |> 
  relocate(sports_balls, .after = last_col())

```

Reading in and cleaning the Professor Trash Wheel dataset:

```{r}

prof_trash = 
  read_excel("2025_trash_data.xlsx", sheet = "Professor Trash Wheel", range = "A2:M120") |> 
  janitor::clean_names()|> 
   mutate(
    day = day(date),
    wheel = "prof") |> 
  select(-date) |> 
  relocate(wheel, .after = dumpster) |> 
  relocate(year, month, day, .after = wheel)

```

Reading in and cleaning the Gwynnda dataset:

```{r}

gwynnda_trash = 
  read_excel("2025_trash_data.xlsx", sheet = "Gwynns Falls Trash Wheel", range = "A2:L265") |> 
  janitor::clean_names() |> 
  mutate(
    day = day(date),
    wheel = "gwynnda") |> 
  select(-date) |> 
  relocate(wheel, .after = dumpster) |> 
  relocate(year, month, day, .after = wheel)

```

Joining the datasets:

```{r}

full_trash = 
  full_join(mr_trash, prof_trash, by = NULL) |> 
  full_join(gwynnda_trash, by = NULL)

```

**Description of the datasets**

The Mr. Trash Wheel, Professor Trash Wheel, and Gwynnda Trash Wheel all provide data on the amount, type, and date of collection of trash by each respective trash wheel as well as the number of homes they powered by running. They all contain the following variables: `r paste(names(prof_trash), collapse = ", ")`. Mr. Trash Wheel also contains a variable for the number of sports balls collected. In the final joined dataset, there are `r nrow(full_trash)` total observations.

For available data, the total weight of trash collected by Professor Trash Wheel was `r sum(full_trash[["weight_tons"]], na.rm = TRUE)` tons.

In June 2022, Gwynnda Trash Wheel collected `r sum(full_trash[["cigarette_butts"]][full_trash[["month"]] == "June" & full_trash[["year"]] == 2022], na.rm = TRUE)` cigarette butts.

# Problem 3

Importing and cleaning the zipcodes dataset:

```{r}

zipcodes_df = 
  read_csv("zillow_data/Zip_Codes.csv", na = c("NA", ".", "")) |> 
  janitor::clean_names() |> 
 mutate(
    file_date = mdy(file_date),
    file_date_year = year(file_date),
    file_date_month = month(file_date),
    file_date_day = day(file_date)
  ) |> 
  select(-file_date) |> 
  relocate(county, zip_code)

```

Importing and cleaning the second dataset:

```{r}

zori_df =
  read_csv("zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv", na = c("NA", ".", "")) %>%
  pivot_longer(
    cols = 10:ncol(.),
    names_to = "date",
    values_to = "price"
  ) %>%
  mutate(
    date = str_remove(date, "^X"),
    date = str_replace_all(date, "_", "-"),
    date = ymd(date),
    year = year(date),
    month = month(date),
    day = day(date)
  ) %>%
  select(1:9, year, month, day, price) %>%
  rename(
    zip_code = RegionName,
    county = CountyName,
    size_rank = SizeRank,
  ) %>%
  select(-StateName, -RegionType) %>%
  mutate(
    county = str_remove(county, " County$")
  ) %>%
  relocate(county, zip_code, year, month, day) %>%
  janitor::clean_names()

```

Joining the two datasets:

```{r}

zillow_df =
  full_join(zori_df, zipcodes_df, by = c("county", "zip_code")) |> 
  relocate(price, .after = last_col()) |> 
  arrange(year, month, day)

```

**Description of the dataset**

The final tidy dataset has `r nrow(zillow_df)` total observations.

There are `r length(unique(zori_df$zip_code))` unique ZIP codes, and `r length(unique(zillow_df$neighborhood))` unique neighborhoods in the dataset.

There are `r length(setdiff(zipcodes_df$zip_code, zori_df$zip_code))` zipcodes that appear in the ZIP code dataset but not in the Zillow Rental Price dataset. 

The ZIP codes in ZIP Codes but not in Zillow Rental Price are: `r paste(setdiff(zipcodes_df$zip_code, zori_df$zip_code), collapse = ", ")`.

Looking at these zip codes, I noticed that many are in Queens County, such as 11423 and 11040, Richmond County (Staten Island), such as 10302 and 10313, Brooklyn County, such as 11252 and 11202, or Bronx County, such as 10464. There are some zipcodes as well in New York County (Manhattan). It may be that these areas have less rental units, either because they are smaller neighborhoods lower in population, or because (in the case of Manhattan), they are in more commercial districts of the city, therefore Zillow would not have rental transaction data to report for these ZIP codes. 

**Comparing prices: January 2021 vs. January 2020**

```{r}

jan_prices_drop = 
  zillow_df |> 
  filter(month == 1, year %in% c(2020, 2021)) |> 
  select(zip_code, county, neighborhood, year, price) |> 
  pivot_wider(
    names_from = year,
    values_from = price,
    names_prefix = "price_"
  ) |> 
  mutate(
    price_drop = price_2021 - price_2020
  ) |> 
  arrange(price_drop) |> 
  select(zip_code, county, neighborhood, price_drop)


jan_prices_drop |> 
  slice_head(n = 10) |> 
  kable(
    col.names = c("ZIP Code", "County", "Neighborhood", "Price Drop"),
    digits = 0
  )

```

Looking at the table showing the 10 ZIP codes with the largest drop in rent price between January 2021 and January 2020, it seems that the areas that experienced the greatest price differentials were in lower Manhattan, in some of the most popular and congested parts of the city. This makes sense, because the during the COVID-19 pandemic, people were wanting to be physically more separated from one another. Additionally, during the pandemic lockdown, people could not take advantage of most of the typical draws of residing in the middle of Manhattan's commercial areas such as easy access to restaurants, bars, offices, and other attractions.